{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isotherms Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_iso1 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/extracted_cm3_per_cm3_values_part1.csv')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# df_iso2 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/extracted_cm3_per_cm3_values_part2.csv')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# df_iso3 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/extracted_cm3_per_cm3_values_part3.csv')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m target_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXe_mol_per_kg_value\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df_iso1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/yll6162/mof_cnn/PSED_data/converted_10bar_5k.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m df_iso2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/yll6162/mof_cnn/PSED_data/converted_10bar_qmof.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m df_iso3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/yll6162/mof_cnn/PSED_data/converted_8k_10bar.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# df_iso1 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/extracted_cm3_per_cm3_values_part1.csv')\n",
    "# df_iso2 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/extracted_cm3_per_cm3_values_part2.csv')\n",
    "# df_iso3 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/extracted_cm3_per_cm3_values_part3.csv')\n",
    "target_col = 'Xe_mol_per_kg_value'\n",
    "output_dir = '/data/yll6162/mof_cnn/data_mix_10bar'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df_iso1 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/converted_10bar_5k.csv')\n",
    "df_iso2 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/converted_10bar_qmof.csv')\n",
    "df_iso3 = pd.read_csv('/data/yll6162/mof_cnn/PSED_data/converted_8k_10bar.csv')\n",
    "df_iso = pd.concat([df_iso1, df_iso2, df_iso3], ignore_index=True)\n",
    "df_iso['database'] = df_iso['project'].apply(lambda x: 'qmof' if x.startswith('qmof') else 'ToBaCCo')\n",
    "df_iso = df_iso[~df_iso[target_col].isna()] # exclude NAN values\n",
    "df_iso.to_csv(f'{output_dir}/all.csv', index=False)\n",
    "df_iso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Grid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted_10bar_5k.csv\t\t\textracted_cm3_per_cm3_values_part3.csv\n",
      "converted_10bar_qmof.csv\t\tNew_Parsed\n",
      "converted_8k_10bar.csv\t\t\tNew_Parsed_new_new.tar.gz\n",
      "extracted_cm3_per_cm3_values_part1.csv\tNew_Parsed.tar.gz\n",
      "extracted_cm3_per_cm3_values_part2.csv\n"
     ]
    }
   ],
   "source": [
    "!ls  /data/yll6162/mof_cnn/PSED_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Integrity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy_grid.txt does not exist in folder: f1_tpt_5_1x1x1\n",
      "energy_grid.txt does not exist in folder: f1_tpt_26_1x1x1\n",
      "energy_grid.txt does not exist in folder: f6_wml_28_1x1x1\n",
      "energy_grid.txt does not exist in folder: f4_ukk_13_1x1x1\n",
      "energy_grid.txt does not exist in folder: f5_tpt_5_1x1x1\n",
      "energy_grid.txt does not exist in folder: f7_tpt_89_1x1x1\n",
      "energy_grid.txt does not exist in folder: f5_tpt_145_1x1x1\n",
      "Absent energy_grid.txt files: 7\n",
      "Empty energy_grid.txt files: 0\n",
      "Abnormal energy_grid.txt files: 1\n",
      "Normal energy_grid.txt files: 13977\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the top-level directory\n",
    "base_dir = \"/data/yll6162/mof_cnn/PSED_data/New_Parsed_new_new/New_Parsed/\" ## REPLACE WITH YOUR DIRECTORY\n",
    "\n",
    "# Define the relative subdirectory and file names to check\n",
    "subdir = \"ASCI_Grids\"\n",
    "file_names = [\"energy_grid.txt\"]\n",
    "abnormal_files = []\n",
    "empty_files = []\n",
    "absent_files = []\n",
    "normal_files = []\n",
    "# Loop through all subdirectories under the base directory\n",
    "for folder in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # Ensure it is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        asci_grids_path = os.path.join(folder_path, subdir)\n",
    "        \n",
    "        # Ensure the ASCI_Grids subdirectory exists\n",
    "        if os.path.exists(asci_grids_path):\n",
    "            # print(f\"\\nProcessing ASCI_Grids in folder: {folder}\")\n",
    "            \n",
    "            # Check for each required file\n",
    "            for file_name in file_names:\n",
    "                file_path = os.path.join(asci_grids_path, file_name)\n",
    "                \n",
    "                # Verify the file exists\n",
    "                if os.path.exists(file_path):\n",
    "                    # print(f\"\\nReading file: {file_name} in folder {folder}\")\n",
    "                    try:\n",
    "                        # Open and print each line of the file\n",
    "                        total_count = 0\n",
    "\n",
    "                        with open(file_path, 'r') as file:\n",
    "                            lines = file.readlines()\n",
    "                            if len(lines) != 68921:\n",
    "                                if len(lines) == 0:\n",
    "                                    empty_files.append(folder)\n",
    "\n",
    "                                # print(f\"Error: {file_name} in folder {folder} has {len(lines)} lines\")\n",
    "                                abnormal_files.append(folder)\n",
    "                                break\n",
    "                            else:\n",
    "                                normal_files.append(folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_name} in folder {folder}: {e}\")\n",
    "                else:\n",
    "                    absent_files.append(folder)\n",
    "                    print(f\"{file_name} does not exist in folder: {folder}\")\n",
    "        else:\n",
    "            print(f\"ASCI_Grids subdirectory does not exist in folder: {folder}\")\n",
    "\n",
    "print(f\"Absent energy_grid.txt files: {len(absent_files)}\")\n",
    "print(f\"Empty energy_grid.txt files: {len(empty_files)}\")\n",
    "print(f\"Abnormal energy_grid.txt files: {len(abnormal_files)}\")\n",
    "print(f\"Normal energy_grid.txt files: {len(normal_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered mofs: 13966\n",
      "Unmatched mofs: 11\n"
     ]
    }
   ],
   "source": [
    "#Filter by isotherm values\n",
    "filterd_mofs = []\n",
    "unmatched_mofs = []\n",
    "for mof_file in normal_files:\n",
    "    if mof_file in df_iso['project'].values:\n",
    "        filterd_mofs.append(mof_file)\n",
    "print(f\"Filtered mofs: {len(filterd_mofs)}\")\n",
    "print(f\"Unmatched mofs: {len(normal_files) - len(filterd_mofs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dataset Split: Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: 12569\n",
      "Testing files: 1397\n",
      "saved train data to /data/yll6162/mof_cnn/data_mix_13k/train/clean.json\n",
      "saved test data to /data/yll6162/mof_cnn/data_mix_13k/test/clean.json\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "test_size = 0.1\n",
    "\n",
    "train_files, test_files = train_test_split(filterd_mofs, test_size=0.1, random_state=42)\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files: {len(test_files)}\")\n",
    "\n",
    "datset_mof = {'train': train_files, 'test': test_files}\n",
    "\n",
    "grid = 41\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    dir_path = os.path.join(output_dir, subset)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    subset_data = {}\n",
    "    subset_data['name'] = datset_mof[subset]\n",
    "    subset_data['grid'] = grid\n",
    "    subset_data['size'] = len(datset_mof[subset])\n",
    "    with open(f'{dir_path}/clean.json', 'w') as f:\n",
    "        json.dump(subset_data, f)\n",
    "    print(f\"saved {subset} data to {dir_path}/clean.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Filter and Merge Energy Grid to Structured Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved train data to /data/yll6162/mof_cnn/data_mix_13k/train/clean.npy\n",
      "saved test data to /data/yll6162/mof_cnn/data_mix_13k/test/clean.npy\n"
     ]
    }
   ],
   "source": [
    "pos_cap = 0\n",
    "source_dir = \"/data/yll6162/mof_cnn/PSED_data/New_Parsed_new_new/New_Parsed\"\n",
    "grid = 41\n",
    "data_splits = [train_files, test_files]\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    array_list = []\n",
    "    dir_path = os.path.join(output_dir, subset)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    for mof_file in datset_mof[subset]:\n",
    "        with open(f\"{source_dir}/{mof_file}/ASCI_Grids/energy_grid.txt\", \"r\") as file:\n",
    "            lines = file.readlines()  # Each line is stored as an element in the list\n",
    "        # Step 1: Convert list to NumPy array\n",
    "        data_array = np.array(lines, dtype=object)\n",
    "        clean_array = np.where(data_array == '?\\n', pos_cap, data_array).astype(float)\n",
    "        cap_array = np.clip(clean_array, None, pos_cap)\n",
    "        reshaped_array = cap_array.reshape((grid, grid, grid))\n",
    "        assert np.isnan(reshaped_array).sum()==0\n",
    "        array_list.append(reshaped_array)\n",
    "\n",
    "    dataset_array = np.stack(array_list, axis=0)\n",
    "    np.save(f\"{dir_path}/clean.npy\", dataset_array)\n",
    "    print(f\"saved {subset} data to {dir_path}/clean.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mof_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
